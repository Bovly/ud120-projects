{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495ea0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(r\"D:\\machine_learning\\ud120-projects\\tools\")\n",
    "from email_preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c25f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6f36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Chris training emails :  7936\n",
      "No. of Sara training emails :  7884\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b524d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 154.325 s\n",
      "prediction time: 0.053 s\n",
      "accuracy: 0.9908987485779295\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "t0 = time()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict on the test\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"prediction time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414f94d",
   "metadata": {},
   "source": [
    "Using the starter code in decision_tree/dt_author_id.py, get a decision tree up and running as a classifier, setting min_samples_split=40. It will probably take a while to train. What’s the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6b9417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 127.219 s\n",
      "prediction time: 0.065 s\n",
      "accuracy: 0.9778156996587031\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "t0 = time()\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict on the test\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"prediction time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b103ab",
   "metadata": {},
   "source": [
    "You found in the SVM mini-project that the parameter tune can significantly speed up the training time of a machine learning algorithm. A general rule is that the parameters can tune the complexity of the algorithm, with more complex algorithms generally running more slowly.\n",
    "\n",
    "Another way to control the complexity of an algorithm is via the number of features that you use in training/testing. The more features the algorithm has available, the more potential there is for a complex fit. We will explore this in detail in the “Feature Selection” lesson, but you’ll get a sneak preview now.\n",
    "\n",
    "What's the number of features in your data? (Hint: the data is organized into a numpy array where the number of rows is the number of data points and the number of columns is the number of features; so to extract this number, use a line of code like len(features_train[0]).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb634bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: (15820, 3785)\n",
      "Number of features: 3785\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "print(\"Number of features:\", features_train.shape)\n",
    "print(\"Number of features:\", len(features_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329db75a",
   "metadata": {},
   "source": [
    "go into ../tools/email_preprocess.py, and find the line of code that looks like this:\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "\n",
    "Change percentile from 10 to 1, and rerun dt_author_id.py. What’s the number of features now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea8cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Chris training emails :  7936\n",
      "No. of Sara training emails :  7884\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(r\"D:\\machine_learning\\ud120-projects\\tools\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82060b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: (15820, 379)\n",
      "Number of features: 379\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "print(\"Number of features:\", features_train.shape)\n",
    "print(\"Number of features:\", len(features_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de040628",
   "metadata": {},
   "source": [
    "What's the accuracy of your decision tree when you use only 1% of your available features (i.e. percentile=1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a6453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 23.33 s\n",
      "prediction time: 0.009 s\n",
      "accuracy: 0.9670079635949943\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "t0 = time()\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict on the test\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"prediction time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
