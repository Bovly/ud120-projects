{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8394be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Chris training emails :  7936\n",
      "No. of Sara training emails :  7884\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project.\n",
    "\n",
    "    Use a SVM to identify emails from the Enron corpus by their authors:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(r\"D:\\machine_learning\\ud120-projects\\tools\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338b00c",
   "metadata": {},
   "source": [
    "Go to the svm directory to find the starter code (svm/svm_author_id.py). Import, create, train and make predictions with the sklearn SVC classifier. When creating the classifier, use a linear kernel (if you forget this step, you will be unpleasantly surprised by how long the classifier takes to train). What is the accuracy of the classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a472845",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code goes here ###\n",
    "# SVM classifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8738b135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 385.116 s\n",
      "Predicting time: 38.287 s\n",
      "Accuracy: 0.9840728100113766\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "clf = SVC(kernel='linear', C= 1.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5a07b",
   "metadata": {},
   "source": [
    "One way to speed up an algorithm is to train it on a smaller training dataset. The tradeoff is that the accuracy almost always goes down when you do this. Let’s explore this more concretely: add in the following two lines immediately before training your classifier.\n",
    "\n",
    "features_train = features_train[:len(features_train)/100] labels_train = labels_train[:len(labels_train)/100]\n",
    "\n",
    "These lines effectively slice the training dataset down to 1% of its original size, tossing out 99% of the training data. You can leave all other code unchanged. What’s the accuracy now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9a3023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.413 s\n",
      "Predicting time: 2.15 s\n",
      "Accuracy: 0.8845278725824801\n"
     ]
    }
   ],
   "source": [
    "features_train = features_train[:int(len(features_train)/100)]\n",
    "labels_train = labels_train[:int(len(labels_train)/100)]\n",
    "\n",
    "# Create classifier\n",
    "clf = SVC(kernel='linear', C= 1.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ab131",
   "metadata": {},
   "source": [
    "Keep the training set slice code from the last quiz, so that you are still training on only 1% of the full training set. Change the kernel of your SVM to “rbf”. What’s the accuracy now, with this more complex kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d04bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.715 s\n",
      "Predicting time: 3.586 s\n",
      "Accuracy: 0.8953356086461889\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 1.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0b96e",
   "metadata": {},
   "source": [
    "Keep the training set size and rbf kernel from the last quiz, but try several values of C (say, 10.0, 100., 1000., and 10000.). Which one gives the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49aaee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.429 s\n",
      "Predicting time: 3.097 s\n",
      "Accuracy: 0.8998862343572241\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 10.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215a98ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.509 s\n",
      "Predicting time: 3.47 s\n",
      "Accuracy: 0.8998862343572241\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 100.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3019f6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.419 s\n",
      "Predicting time: 3.308 s\n",
      "Accuracy: 0.8998862343572241\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 1000.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023c04c",
   "metadata": {},
   "source": [
    "C=10000 gives the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ef617",
   "metadata": {},
   "source": [
    "Once you've optimized the C value for your RBF kernel, what accuracy does it give? Does this C value correspond to a simpler or more complex decision boundary?\n",
    "\n",
    "(If you're not sure about the complexity, go back a few videos to the \"SVM C Parameter\" part of the lesson. The result that you found there is also applicable here, even though it's now much harder or even impossible to draw the decision boundary in a simple scatterplot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f22ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More complex decision boundary\n"
     ]
    }
   ],
   "source": [
    "print('More complex decision boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3c26c",
   "metadata": {},
   "source": [
    "Now that you’ve optimized C for the RBF kernel, go back to using the full training set. In general, having a larger training set will improve the performance of your algorithm, so (by tuning C and training on a large dataset) we should get a fairly optimized result. What is the accuracy of the optimized SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2de8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Chris training emails :  7936\n",
      "No. of Sara training emails :  7884\n",
      "Training time: 423.775 s\n",
      "Predicting time: 54.614 s\n",
      "Accuracy: 0.9960182025028441\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 1000.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a19884d",
   "metadata": {},
   "source": [
    "What class does your SVM (0 or 1, corresponding to Sara and Chris respectively) predict for element 10 of the test set? The 26th? The 50th? (Use the RBF kernel, C=10000, and 1% of the training set. Normally you'd get the best results using the full training set, but we found that using 1% sped up the computation considerably and did not change our results--so feel free to use that shortcut here.)\n",
    "\n",
    "And just to be clear, the data point numbers that we give here (10, 26, 50) assume a zero-indexed list. So the correct answer for element #100 would be found using something like answer=predictions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ef4c4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.526 s\n",
      "Predicting time: 3.55 s\n",
      "Accuracy: 0.8998862343572241\n"
     ]
    }
   ],
   "source": [
    "features_train = features_train[:int(len(features_train)/100)]\n",
    "labels_train = labels_train[:int(len(labels_train)/100)]\n",
    "\n",
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 1000.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c85cfee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for element 10th, 26th and 50th are: [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction for element 10th, 26th and 50th are:\", pred[[10, 26, 50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86739d2",
   "metadata": {},
   "source": [
    "There are over 1700 test events--how many are predicted to be in the “Chris” (1) class? (Use the RBF kernel, C=10000., and the full training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ec1e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Chris training emails :  7936\n",
      "No. of Sara training emails :  7884\n",
      "Training time: 367.897 s\n",
      "Predicting time: 49.927 s\n",
      "Accuracy: 0.9960182025028441\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "# Create classifier\n",
    "clf = SVC(kernel='rbf', C= 10000.0)\n",
    "\n",
    "# Train\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print(\"Training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "# Predict\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\")\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5554c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails predicted to be from Chris (1): 866\n"
     ]
    }
   ],
   "source": [
    "# Count of Chris\n",
    "num_chris = sum(pred == 1)\n",
    "print(\"Number of emails predicted to be from Chris (1):\", num_chris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
